
# 🔍 AI Audit of M5 Forecasting System

**Project Title:**  
AI Clarity Project – Auditing Forecast Accuracy Using SHAP, LIME, and DiCE  
**Status:** Completed Audit Simulation | Public Educational Initiative

---

## 🧠 Overview

This project simulates a comprehensive audit of an AI-driven Automated Decision-Making (ADM) system using the publicly available **M5 Forecasting Accuracy dataset** from Kaggle. The audit focused on verifying explainability, traceability, and governance compliance across a retail sales forecasting system that influenced critical business functions like inventory, pricing, and staffing.

---

## 🎯 Objectives

- Identify which input variables most influenced sales forecasts
- Evaluate if decisions aligned with governance boundaries and business control
- Use **SHAP**, **LIME**, and **DiCE** to explain and validate model behavior
- Test ADM output stability, fairness, and traceability
- Align findings with:
  - 🇪🇺 **EU AI Act** (Articles 13 & 14)
  - 🇺🇸 **NIST AI Risk Management Framework (RMF)**
  - 🌐 **OECD AI Principles**
  - 🔎 **NIST Principles of Explainable AI**

---

## 🗂️ Project Structure

- `M5_Forecasting_Audit_Final_Notebook_v2.ipynb`: Final Colab notebook with version-controlled cells, commentary, and output
- `audit_visuals/`: Folder containing audit visuals formatted for Flourish Studio and LinkedIn
- `outputs/`: Includes CSVs with SHAP, LIME, and DiCE explanations
- `AI_Clarity_Audit_Workpaper_Template.docx`: Best-in-class audit documentation template
- `README.md`: This file

---

## ✅ Key Features

- 4.5 years of retail data audited (2020–2025)
- 75M+ records | $300M+ sales | 3,000+ items
- End-to-end traceability: raw data → ADM → explainability tools → audit conclusions
- Defensive coding, governance-first logic, and counterfactual testing

---

## 📊 Results

- Found key drivers for sales (e.g., day-of-week, price, promotion)
- Visualized counterfactuals showing how small changes flip ADM decisions
- Identified potential risks in inconsistent tool agreement
- Documented every step for reproducibility and compliance

---

## 👤 Author

David Cortright  
Founder of the **AI Clarity Project**  
🔎 _“Illuminating AI. Clarifying Risk.”_  
🧭 A voluntary initiative exploring AI transparency and decision governance.

---

## 🔗 Links

- 🔗 [LinkedIn Post Series](https://linkedin.com) _(Add link when published)_
- 📘 [PDF Summary (Executive-Ready)](https://example.com/pdf) _(Optional if hosting PDF externally)_
- 🧾 [Audit Template](AI_Clarity_Audit_Workpaper_Template.docx)

---

## 📜 Certifications

- Certified AI & Algorithm Auditor (BABL AI)  
- Certified Information Systems Security Professional (CISSP)  
- Certified Internal Auditor (CIA)  
- NIST AI RMF Architect Certified

---

## 📥 How to Use

```bash
# Clone the repository
git clone https://github.com/YOUR-USERNAME/m5-forecasting-ai-audit.git

# Open the notebook in Google Colab or JupyterLab
```

---

## 📄 License

This is a public, educational project and does not represent any employer.  
No proprietary models or sensitive business data were used.
---

## 📄 License

This project is open source and available under the [MIT License](./LICENSE).

