
# ğŸ” AI Audit of M5 Forecasting System

**Project Title:**  
AI Clarity Project â€“ Auditing Forecast Accuracy Using SHAP, LIME, and DiCE  
**Status:** Completed Audit Simulation | Public Educational Initiative

---

## ğŸ§  Overview

This project simulates a comprehensive audit of an AI-driven Automated Decision-Making (ADM) system using the publicly available **M5 Forecasting Accuracy dataset** from Kaggle. The audit focused on verifying explainability, traceability, and governance compliance across a retail sales forecasting system that influenced critical business functions like inventory, pricing, and staffing.

---

## ğŸ¯ Objectives

- Identify which input variables most influenced sales forecasts
- Evaluate if decisions aligned with governance boundaries and business control
- Use **SHAP**, **LIME**, and **DiCE** to explain and validate model behavior
- Test ADM output stability, fairness, and traceability
- Align findings with:
  - ğŸ‡ªğŸ‡º **EU AI Act** (Articles 13 & 14)
  - ğŸ‡ºğŸ‡¸ **NIST AI Risk Management Framework (RMF)**
  - ğŸŒ **OECD AI Principles**
  - ğŸ” **NIST Principles of Explainable AI**

---

## ğŸ—‚ï¸ Project Structure

- `M5_Forecasting_Audit_Final_Notebook_v2.ipynb`: Final Colab notebook with version-controlled cells, commentary, and output
- `audit_visuals/`: Folder containing audit visuals formatted for Flourish Studio and LinkedIn
- `outputs/`: Includes CSVs with SHAP, LIME, and DiCE explanations
- `AI_Clarity_Audit_Workpaper_Template.docx`: Best-in-class audit documentation template
- `README.md`: This file

---

## âœ… Key Features

- 4.5 years of retail data audited (2020â€“2025)
- 75M+ records | $300M+ sales | 3,000+ items
- End-to-end traceability: raw data â†’ ADM â†’ explainability tools â†’ audit conclusions
- Defensive coding, governance-first logic, and counterfactual testing

---

## ğŸ“Š Results

- Found key drivers for sales (e.g., day-of-week, price, promotion)
- Visualized counterfactuals showing how small changes flip ADM decisions
- Identified potential risks in inconsistent tool agreement
- Documented every step for reproducibility and compliance

---

## ğŸ‘¤ Author

David Cortright  
Founder of the **AI Clarity Project**  
ğŸ” _â€œIlluminating AI. Clarifying Risk.â€_  
ğŸ§­ A voluntary initiative exploring AI transparency and decision governance.

---

## ğŸ”— Links

- ğŸ”— [LinkedIn Post Series](https://linkedin.com) _(Add link when published)_
- ğŸ“˜ [PDF Summary (Executive-Ready)](https://example.com/pdf) _(Optional if hosting PDF externally)_
- ğŸ§¾ [Audit Template](AI_Clarity_Audit_Workpaper_Template.docx)

---

## ğŸ“œ Certifications

- Certified AI & Algorithm Auditor (BABL AI)  
- Certified Information Systems Security Professional (CISSP)  
- Certified Internal Auditor (CIA)  
- NIST AI RMF Architect Certified

---

## ğŸ“¥ How to Use

```bash
# Clone the repository
git clone https://github.com/YOUR-USERNAME/m5-forecasting-ai-audit.git

# Open the notebook in Google Colab or JupyterLab
```

---

## ğŸ“„ License

This is a public, educational project and does not represent any employer.  
No proprietary models or sensitive business data were used.
---

## ğŸ“„ License

This project is open source and available under the [MIT License](./LICENSE).

